"""
ì˜¤ë””ì˜¤ ë¶„ì„ - ë¹„íŠ¸ ë° ê°•ì¡° íƒ€ì´ë° ì¶”ì¶œ
"""
import librosa
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Tuple


class AudioAnalyzer:
    """ì˜¤ë””ì˜¤ ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self, config: Dict[str, Any]):
        """
        ì´ˆê¸°í™”

        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.config = config
        self.audio_config = config.get('audio', {})
        self.hop_length = self.audio_config.get('hop_length', 512)
        self.onset_threshold = self.audio_config.get('onset_threshold', 0.5)
        self.beat_threshold = self.audio_config.get('beat_threshold', 0.3)

    def analyze(self, audio_path: Path, target_duration: float = None) -> Dict[str, Any]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ ë¶„ì„í•˜ì—¬ ë¹„íŠ¸ ë° ê°•ì¡° íƒ€ì´ë° ì¶”ì¶œ

        Args:
            audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            target_duration: ëª©í‘œ ê¸¸ì´ (Noneì´ë©´ ì „ì²´ ì‚¬ìš©)

        Returns:
            {
                "duration": float,  # ì˜¤ë””ì˜¤ ê¸¸ì´
                "tempo": float,  # BPM
                "beats": List[float],  # ë¹„íŠ¸ íƒ€ì´ë° (ì´ˆ)
                "onsets": List[float],  # ê°•ì¡° íƒ€ì´ë° (ì´ˆ)
                "scene_timings": List[float],  # ì¥ë©´ ì „í™˜ íƒ€ì´ë° (ì´ˆ)
                "sr": int  # ìƒ˜í”Œë§ ë ˆì´íŠ¸
            }
        """
        print("\nğŸµ ì˜¤ë””ì˜¤ ë¶„ì„ ì¤‘...")
        print(f"  íŒŒì¼: {audio_path.name}")

        try:
            # ì˜¤ë””ì˜¤ ë¡œë“œ
            y, sr = librosa.load(str(audio_path), sr=None)
            duration = librosa.get_duration(y=y, sr=sr)

            # ëª©í‘œ ê¸¸ì´ê°€ ì§€ì •ë˜ë©´ ì˜ë¼ë‚´ê¸°
            if target_duration and target_duration < duration:
                y = y[:int(target_duration * sr)]
                duration = target_duration

            print(f"  ê¸¸ì´: {duration:.2f}ì´ˆ")
            print(f"  ìƒ˜í”Œë§ ë ˆì´íŠ¸: {sr}Hz")

            # í…œí¬ ë° ë¹„íŠ¸ ê°ì§€
            tempo, beats = self._detect_beats(y, sr)
            print(f"  í…œí¬: {tempo:.1f} BPM")
            print(f"  ë¹„íŠ¸: {len(beats)}ê°œ")

            # ê°•ì¡° ì§€ì  ê°ì§€ (onset detection)
            onsets = self._detect_onsets(y, sr)
            print(f"  ê°•ì¡° ì§€ì : {len(onsets)}ê°œ")

            # ì¥ë©´ ì „í™˜ íƒ€ì´ë° ê³„ì‚°
            scene_timings = self._calculate_scene_timings(beats, onsets, duration)
            print(f"  ì¥ë©´ ì „í™˜ íƒ€ì´ë°: {len(scene_timings)}ê°œ")

            return {
                "duration": duration,
                "tempo": tempo,
                "beats": beats,
                "onsets": onsets,
                "scene_timings": scene_timings,
                "sr": sr
            }

        except Exception as e:
            print(f"  âœ— ì˜¤ë””ì˜¤ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None

    def _detect_beats(self, y: np.ndarray, sr: int) -> Tuple[float, List[float]]:
        """
        ë¹„íŠ¸ ê°ì§€

        Args:
            y: ì˜¤ë””ì˜¤ ì‹ í˜¸
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸

        Returns:
            (tempo, beat_times)
        """
        # í…œí¬ ë° ë¹„íŠ¸ í”„ë ˆì„ ì¶”ì¶œ
        tempo, beat_frames = librosa.beat.beat_track(
            y=y,
            sr=sr,
            hop_length=self.hop_length
        )

        # í”„ë ˆì„ì„ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
        beat_times = librosa.frames_to_time(
            beat_frames,
            sr=sr,
            hop_length=self.hop_length
        )

        return float(tempo), beat_times.tolist()

    def _detect_onsets(self, y: np.ndarray, sr: int) -> List[float]:
        """
        ê°•ì¡° ì§€ì  ê°ì§€ (onset detection)

        Args:
            y: ì˜¤ë””ì˜¤ ì‹ í˜¸
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸

        Returns:
            onset_times
        """
        # Onset strength envelope ê³„ì‚°
        onset_env = librosa.onset.onset_strength(
            y=y,
            sr=sr,
            hop_length=self.hop_length
        )

        # Onset ê°ì§€
        onset_frames = librosa.onset.onset_detect(
            onset_envelope=onset_env,
            sr=sr,
            hop_length=self.hop_length,
            backtrack=True,
            normalize=True
        )

        # í”„ë ˆì„ì„ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
        onset_times = librosa.frames_to_time(
            onset_frames,
            sr=sr,
            hop_length=self.hop_length
        )

        return onset_times.tolist()

    def _calculate_scene_timings(
        self,
        beats: List[float],
        onsets: List[float],
        duration: float
    ) -> List[float]:
        """
        ì¥ë©´ ì „í™˜ íƒ€ì´ë° ê³„ì‚° (ë¹„íŠ¸ì™€ ê°•ì¡° ì§€ì  ê²°í•©)

        Args:
            beats: ë¹„íŠ¸ íƒ€ì´ë°
            onsets: ê°•ì¡° íƒ€ì´ë°
            duration: ì „ì²´ ê¸¸ì´

        Returns:
            scene_timings
        """
        # ë¹„íŠ¸ì™€ ê°•ì¡° ì§€ì ì„ í•©ì¹˜ê³  ì •ë ¬
        all_timings = sorted(set(beats + onsets))

        # ë„ˆë¬´ ê°€ê¹Œìš´ íƒ€ì´ë° í•„í„°ë§ (ìµœì†Œ ê°„ê²©)
        min_interval = self.audio_config.get('min_scene_interval', 0.5)
        filtered_timings = []
        last_time = -min_interval

        for time in all_timings:
            if time - last_time >= min_interval:
                filtered_timings.append(time)
                last_time = time

        # 0.0ì´ ì—†ìœ¼ë©´ ì¶”ê°€
        if not filtered_timings or filtered_timings[0] > 0.1:
            filtered_timings.insert(0, 0.0)

        return filtered_timings

    def distribute_scenes_to_timings(
        self,
        num_scenes: int,
        audio_analysis: Dict[str, Any],
        strategy: str = "auto"
    ) -> List[Tuple[int, float, float]]:
        """
        ì¥ë©´ë“¤ì„ ì˜¤ë””ì˜¤ íƒ€ì´ë°ì— ë§ì¶° ë°°ì¹˜

        Args:
            num_scenes: ì¥ë©´ ê°œìˆ˜
            audio_analysis: ì˜¤ë””ì˜¤ ë¶„ì„ ê²°ê³¼
            strategy: ë°°ì¹˜ ì „ëµ
                - "auto": ìë™ (ì¥ë©´ ìˆ˜ì— ë§ì¶°)
                - "evenly": ê· ë“± ë°°ì¹˜
                - "beats": ë¹„íŠ¸ì— ë§ì¶°
                - "onsets": ê°•ì¡° ì§€ì ì— ë§ì¶°

        Returns:
            [(scene_index, start_time, duration), ...]
        """
        scene_timings = audio_analysis['scene_timings']
        duration = audio_analysis['duration']

        if strategy == "evenly":
            # ê· ë“± ë¶„í• 
            scene_duration = duration / num_scenes
            return [
                (i, i * scene_duration, scene_duration)
                for i in range(num_scenes)
            ]

        elif strategy == "beats":
            # ë¹„íŠ¸ì— ë§ì¶°
            timings = audio_analysis['beats']
        elif strategy == "onsets":
            # ê°•ì¡° ì§€ì ì— ë§ì¶°
            timings = audio_analysis['onsets']
        else:
            # auto: scene_timings ì‚¬ìš©
            timings = scene_timings

        # ì¥ë©´ ìˆ˜ì— ë§ì¶° íƒ€ì´ë° ì„ íƒ
        if len(timings) < num_scenes:
            # íƒ€ì´ë°ì´ ë¶€ì¡±í•˜ë©´ ê· ë“± ë¶„í• 
            print(f"  âš ï¸  íƒ€ì´ë°({len(timings)}ê°œ)ì´ ì¥ë©´({num_scenes}ê°œ)ë³´ë‹¤ ì ì–´ ê· ë“± ë¶„í•  ì‚¬ìš©")
            scene_duration = duration / num_scenes
            return [
                (i, i * scene_duration, scene_duration)
                for i in range(num_scenes)
            ]

        # íƒ€ì´ë°ì´ ë§ìœ¼ë©´ ê· ë“± ê°„ê²©ìœ¼ë¡œ ìƒ˜í”Œë§
        selected_indices = np.linspace(0, len(timings) - 1, num_scenes, dtype=int)
        selected_timings = [timings[i] for i in selected_indices]

        # ê° ì¥ë©´ì˜ ì‹œì‘ ì‹œê°„ê³¼ ê¸¸ì´ ê³„ì‚°
        result = []
        for i in range(num_scenes):
            start_time = selected_timings[i]

            # ë‹¤ìŒ ì¥ë©´ì´ ìˆìœ¼ë©´ ê·¸ ì‹œì‘ ì‹œê°„ê¹Œì§€, ì—†ìœ¼ë©´ ëê¹Œì§€
            if i < num_scenes - 1:
                end_time = selected_timings[i + 1]
            else:
                end_time = duration

            scene_duration = end_time - start_time
            result.append((i, start_time, scene_duration))

        return result

    def trim_audio(
        self,
        audio_path: Path,
        output_path: Path,
        target_duration: float
    ) -> bool:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ ëª©í‘œ ê¸¸ì´ë¡œ ìë¥´ê¸°

        Args:
            audio_path: ì…ë ¥ ì˜¤ë””ì˜¤ ê²½ë¡œ
            output_path: ì¶œë ¥ ì˜¤ë””ì˜¤ ê²½ë¡œ
            target_duration: ëª©í‘œ ê¸¸ì´ (ì´ˆ)

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            import soundfile as sf

            # ì˜¤ë””ì˜¤ ë¡œë“œ
            y, sr = librosa.load(str(audio_path), sr=None)

            # ëª©í‘œ ê¸¸ì´ë¡œ ìë¥´ê¸°
            target_samples = int(target_duration * sr)
            y_trimmed = y[:target_samples]

            # ì €ì¥
            sf.write(str(output_path), y_trimmed, sr)

            print(f"  âœ“ ì˜¤ë””ì˜¤ íŠ¸ë¦¬ë° ì™„ë£Œ: {target_duration:.2f}ì´ˆ")
            return True

        except Exception as e:
            print(f"  âœ— ì˜¤ë””ì˜¤ íŠ¸ë¦¬ë° ì‹¤íŒ¨: {e}")
            return False
